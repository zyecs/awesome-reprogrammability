{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Awesome Neural Network Reprogrammability \u00b6 Welcome to the comprehensive documentation for neural network reprogrammability resources. Overview \u00b6 Neural network reprogrammability refers to methods that enable pre-trained neural networks to be adapted for new tasks with minimal parameter updates, leveraging existing learned representations. Navigation \u00b6 Papers - Tabular view organized by reprogrammability taxonomy dimensions Taxonomy - Classification system for reprogrammability methods Evaluations - Benchmark results and comparisons Quick Start \u00b6 Browse the main README for the complete curated list of papers, datasets, and tools.","title":"Home"},{"location":"#awesome-neural-network-reprogrammability","text":"Welcome to the comprehensive documentation for neural network reprogrammability resources.","title":"Awesome Neural Network Reprogrammability"},{"location":"#overview","text":"Neural network reprogrammability refers to methods that enable pre-trained neural networks to be adapted for new tasks with minimal parameter updates, leveraging existing learned representations.","title":"Overview"},{"location":"#navigation","text":"Papers - Tabular view organized by reprogrammability taxonomy dimensions Taxonomy - Classification system for reprogrammability methods Evaluations - Benchmark results and comparisons","title":"Navigation"},{"location":"#quick-start","text":"Browse the main README for the complete curated list of papers, datasets, and tools.","title":"Quick Start"},{"location":"RESOURCE_TEMPLATES/","text":"Resource Templates \u00b6 This document provides templates for adding new resources to the Awesome Neural Network Reprogrammability list. Please follow these templates to ensure consistency and quality. \ud83d\udcc4 Research Paper Template \u00b6 - **[Paper Title](paper-url)** (Authors et al., Year, Venue) - Brief description highlighting key contribution or novelty - \ud83d\udcca **Taxonomy**: Configuration | Location | Operator | Alignment - \ud83d\udd17 **Code**: [repository-name](code-url) (if available) - \ud83d\udcd6 **Dataset**: [dataset-name](dataset-url) (if provided) Example: - **[Adversarial Reprogramming of Neural Networks](https://arxiv.org/abs/1806.11146)** (Elsayed et al., 2019, ICLR) - Seminal work introducing adversarial reprogramming for cross-task transfer - \ud83d\udcca **Taxonomy**: Learnable | Input | Additive | Statistical - \ud83d\udd17 **Code**: Available in supplementary materials \ud83d\udee0\ufe0f Tool/Library Template \u00b6 - **[Tool Name](tool-url)** - Comprehensive description of what the tool does, its main features, and supported use cases - \ud83c\udff7\ufe0f **Category**: Framework/Library/Development Tool/Evaluation - \ud83d\udcbb **Language**: Primary programming language - \ud83d\udcda **Documentation**: [docs-url](documentation-link) - \u2b50 **Stars**: Current GitHub star count (if applicable) - \ud83c\udfc3 **Status**: Active/Maintained/Archived Example: - **[OpenPrompt](https://github.com/thunlp/OpenPrompt)** - Comprehensive framework for prompt learning with support for multiple models and prompt types - \ud83c\udff7\ufe0f **Category**: Framework - \ud83d\udcbb **Language**: Python - \ud83d\udcda **Documentation**: See GitHub README - \u2b50 **Stars**: 4.2k+ - \ud83c\udfc3 **Status**: Active \ud83d\udcca Dataset/Benchmark Template \u00b6 - **[Dataset Name](dataset-url)** - Description of the dataset, its purpose, and key characteristics - \ud83d\udccf **Size**: Number of samples/images/examples - \ud83c\udff7\ufe0f **Domain**: Computer Vision/NLP/Audio/Multimodal - \ud83c\udfaf **Task**: Specific task type (classification, detection, etc.) - \ud83d\udcc4 **Paper**: [paper-title](paper-url) - \ud83d\udcbe **Download**: [download-link](download-url) Example: - **[MetaDataset](https://github.com/google-research/meta-dataset)** - Large-scale meta-learning benchmark for few-shot classification - \ud83d\udccf **Size**: 10 datasets, 1000+ classes - \ud83c\udff7\ufe0f **Domain**: Computer Vision - \ud83c\udfaf **Task**: Few-shot classification - \ud83d\udcc4 **Paper**: [Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples](https://arxiv.org/abs/1903.03096) - \ud83d\udcbe **Download**: See GitHub repository for installation instructions \ud83d\udcd6 Educational Resource Template \u00b6 - **[Resource Title](resource-url)** - Description of the educational content and target audience - \ud83c\udff7\ufe0f **Type**: Tutorial/Course/Book/Video/Workshop - \ud83c\udf93 **Level**: Beginner/Intermediate/Advanced - \u23f1\ufe0f **Duration**: Estimated time to complete (for courses/tutorials) - \ud83d\udc65 **Author**: Creator or institution - \ud83d\udcb0 **Cost**: Free/Paid Example: - **[Prompt Engineering Course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)** - Hands-on course covering prompt design patterns and best practices - \ud83c\udff7\ufe0f **Type**: Course - \ud83c\udf93 **Level**: Beginner to Intermediate - \u23f1\ufe0f **Duration**: ~2 hours - \ud83d\udc65 **Author**: DeepLearning.AI - \ud83d\udcb0 **Cost**: Free \ud83d\ude80 Application/Implementation Template \u00b6 - **[Project Name](project-url)** - Description of the application, problem solved, and approach used - \ud83c\udff7\ufe0f **Category**: Real-world Application/Demo/Implementation - \ud83d\udd27 **Method**: Model Reprogramming/Prompt Tuning/Prompt Instruction - \ud83c\udfaf **Domain**: Application domain - \ud83d\udcca **Results**: Key performance metrics or achievements - \ud83d\udd17 **Code**: [repository](code-url) (if available) Example: - **[Time-LLM](https://github.com/KimMeen/Time-LLM)** - Time series forecasting by reprogramming large language models - \ud83c\udff7\ufe0f **Category**: Implementation - \ud83d\udd27 **Method**: Model Reprogramming - \ud83c\udfaf **Domain**: Time Series Analysis - \ud83d\udcca **Results**: SOTA on 7/8 forecasting benchmarks - \ud83d\udd17 **Code**: [Time-LLM](https://github.com/KimMeen/Time-LLM) \ud83d\udd2c Evaluation Guidelines \u00b6 When adding resources, ensure they meet these quality criteria: For Papers: \u00b6 [ ] Published in reputable venue (conference/journal) or high-quality preprint [ ] Clear contribution to neural network reprogrammability [ ] Reproducible results with available code/data (preferred) [ ] Proper taxonomy classification For Tools: \u00b6 [ ] Well-documented with clear installation instructions [ ] Active maintenance or stable release [ ] Relevant to the reprogrammability community [ ] Working links and accessible repositories For Datasets: \u00b6 [ ] Publicly available and accessible [ ] Clear documentation and usage instructions [ ] Relevant to reprogrammability evaluation [ ] Proper licensing information For Educational Resources: \u00b6 [ ] High-quality, accurate content [ ] Clear learning objectives [ ] Appropriate for stated skill level [ ] Accessible to the target audience \ud83d\udcdd Submission Checklist \u00b6 Before submitting a new resource: Choose the appropriate template based on resource type Fill in all required fields with accurate information Verify all links are working and accessible Check for duplicates in the existing list Ensure quality standards are met Place in correct section based on resource type and taxonomy Use consistent formatting following the template Add brief but informative description highlighting key aspects \ud83c\udff7\ufe0f Taxonomy Classification Guide \u00b6 For research papers, classify using the four-dimensional taxonomy: Configuration (\u03bb) : Learnable, Fixed, or Hybrid Location (\u2113) : Input, Embedding, Hidden, or Output Operator (\u03c4) : Additive, Concatenative, Parametric, or Replacement Alignment (\u03c9) : Identity, Linear, Statistical, or Rule-based Refer to meta/taxonomy.md for detailed explanations of each dimension. \ud83d\udcde Questions? \u00b6 If you're unsure about: - Resource classification or taxonomy - Quality standards or requirements - Template usage or formatting Please open an issue for clarification before submitting your contribution.","title":"Resource Templates"},{"location":"RESOURCE_TEMPLATES/#resource-templates","text":"This document provides templates for adding new resources to the Awesome Neural Network Reprogrammability list. Please follow these templates to ensure consistency and quality.","title":"Resource Templates"},{"location":"RESOURCE_TEMPLATES/#research-paper-template","text":"- **[Paper Title](paper-url)** (Authors et al., Year, Venue) - Brief description highlighting key contribution or novelty - \ud83d\udcca **Taxonomy**: Configuration | Location | Operator | Alignment - \ud83d\udd17 **Code**: [repository-name](code-url) (if available) - \ud83d\udcd6 **Dataset**: [dataset-name](dataset-url) (if provided) Example: - **[Adversarial Reprogramming of Neural Networks](https://arxiv.org/abs/1806.11146)** (Elsayed et al., 2019, ICLR) - Seminal work introducing adversarial reprogramming for cross-task transfer - \ud83d\udcca **Taxonomy**: Learnable | Input | Additive | Statistical - \ud83d\udd17 **Code**: Available in supplementary materials","title":"\ud83d\udcc4 Research Paper Template"},{"location":"RESOURCE_TEMPLATES/#toollibrary-template","text":"- **[Tool Name](tool-url)** - Comprehensive description of what the tool does, its main features, and supported use cases - \ud83c\udff7\ufe0f **Category**: Framework/Library/Development Tool/Evaluation - \ud83d\udcbb **Language**: Primary programming language - \ud83d\udcda **Documentation**: [docs-url](documentation-link) - \u2b50 **Stars**: Current GitHub star count (if applicable) - \ud83c\udfc3 **Status**: Active/Maintained/Archived Example: - **[OpenPrompt](https://github.com/thunlp/OpenPrompt)** - Comprehensive framework for prompt learning with support for multiple models and prompt types - \ud83c\udff7\ufe0f **Category**: Framework - \ud83d\udcbb **Language**: Python - \ud83d\udcda **Documentation**: See GitHub README - \u2b50 **Stars**: 4.2k+ - \ud83c\udfc3 **Status**: Active","title":"\ud83d\udee0\ufe0f Tool/Library Template"},{"location":"RESOURCE_TEMPLATES/#datasetbenchmark-template","text":"- **[Dataset Name](dataset-url)** - Description of the dataset, its purpose, and key characteristics - \ud83d\udccf **Size**: Number of samples/images/examples - \ud83c\udff7\ufe0f **Domain**: Computer Vision/NLP/Audio/Multimodal - \ud83c\udfaf **Task**: Specific task type (classification, detection, etc.) - \ud83d\udcc4 **Paper**: [paper-title](paper-url) - \ud83d\udcbe **Download**: [download-link](download-url) Example: - **[MetaDataset](https://github.com/google-research/meta-dataset)** - Large-scale meta-learning benchmark for few-shot classification - \ud83d\udccf **Size**: 10 datasets, 1000+ classes - \ud83c\udff7\ufe0f **Domain**: Computer Vision - \ud83c\udfaf **Task**: Few-shot classification - \ud83d\udcc4 **Paper**: [Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples](https://arxiv.org/abs/1903.03096) - \ud83d\udcbe **Download**: See GitHub repository for installation instructions","title":"\ud83d\udcca Dataset/Benchmark Template"},{"location":"RESOURCE_TEMPLATES/#educational-resource-template","text":"- **[Resource Title](resource-url)** - Description of the educational content and target audience - \ud83c\udff7\ufe0f **Type**: Tutorial/Course/Book/Video/Workshop - \ud83c\udf93 **Level**: Beginner/Intermediate/Advanced - \u23f1\ufe0f **Duration**: Estimated time to complete (for courses/tutorials) - \ud83d\udc65 **Author**: Creator or institution - \ud83d\udcb0 **Cost**: Free/Paid Example: - **[Prompt Engineering Course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)** - Hands-on course covering prompt design patterns and best practices - \ud83c\udff7\ufe0f **Type**: Course - \ud83c\udf93 **Level**: Beginner to Intermediate - \u23f1\ufe0f **Duration**: ~2 hours - \ud83d\udc65 **Author**: DeepLearning.AI - \ud83d\udcb0 **Cost**: Free","title":"\ud83d\udcd6 Educational Resource Template"},{"location":"RESOURCE_TEMPLATES/#applicationimplementation-template","text":"- **[Project Name](project-url)** - Description of the application, problem solved, and approach used - \ud83c\udff7\ufe0f **Category**: Real-world Application/Demo/Implementation - \ud83d\udd27 **Method**: Model Reprogramming/Prompt Tuning/Prompt Instruction - \ud83c\udfaf **Domain**: Application domain - \ud83d\udcca **Results**: Key performance metrics or achievements - \ud83d\udd17 **Code**: [repository](code-url) (if available) Example: - **[Time-LLM](https://github.com/KimMeen/Time-LLM)** - Time series forecasting by reprogramming large language models - \ud83c\udff7\ufe0f **Category**: Implementation - \ud83d\udd27 **Method**: Model Reprogramming - \ud83c\udfaf **Domain**: Time Series Analysis - \ud83d\udcca **Results**: SOTA on 7/8 forecasting benchmarks - \ud83d\udd17 **Code**: [Time-LLM](https://github.com/KimMeen/Time-LLM)","title":"\ud83d\ude80 Application/Implementation Template"},{"location":"RESOURCE_TEMPLATES/#evaluation-guidelines","text":"When adding resources, ensure they meet these quality criteria:","title":"\ud83d\udd2c Evaluation Guidelines"},{"location":"RESOURCE_TEMPLATES/#for-papers","text":"[ ] Published in reputable venue (conference/journal) or high-quality preprint [ ] Clear contribution to neural network reprogrammability [ ] Reproducible results with available code/data (preferred) [ ] Proper taxonomy classification","title":"For Papers:"},{"location":"RESOURCE_TEMPLATES/#for-tools","text":"[ ] Well-documented with clear installation instructions [ ] Active maintenance or stable release [ ] Relevant to the reprogrammability community [ ] Working links and accessible repositories","title":"For Tools:"},{"location":"RESOURCE_TEMPLATES/#for-datasets","text":"[ ] Publicly available and accessible [ ] Clear documentation and usage instructions [ ] Relevant to reprogrammability evaluation [ ] Proper licensing information","title":"For Datasets:"},{"location":"RESOURCE_TEMPLATES/#for-educational-resources","text":"[ ] High-quality, accurate content [ ] Clear learning objectives [ ] Appropriate for stated skill level [ ] Accessible to the target audience","title":"For Educational Resources:"},{"location":"RESOURCE_TEMPLATES/#submission-checklist","text":"Before submitting a new resource: Choose the appropriate template based on resource type Fill in all required fields with accurate information Verify all links are working and accessible Check for duplicates in the existing list Ensure quality standards are met Place in correct section based on resource type and taxonomy Use consistent formatting following the template Add brief but informative description highlighting key aspects","title":"\ud83d\udcdd Submission Checklist"},{"location":"RESOURCE_TEMPLATES/#taxonomy-classification-guide","text":"For research papers, classify using the four-dimensional taxonomy: Configuration (\u03bb) : Learnable, Fixed, or Hybrid Location (\u2113) : Input, Embedding, Hidden, or Output Operator (\u03c4) : Additive, Concatenative, Parametric, or Replacement Alignment (\u03c9) : Identity, Linear, Statistical, or Rule-based Refer to meta/taxonomy.md for detailed explanations of each dimension.","title":"\ud83c\udff7\ufe0f Taxonomy Classification Guide"},{"location":"RESOURCE_TEMPLATES/#questions","text":"If you're unsure about: - Resource classification or taxonomy - Quality standards or requirements - Template usage or formatting Please open an issue for clarification before submitting your contribution.","title":"\ud83d\udcde Questions?"},{"location":"sections/evaluations/","text":"Evaluations \u00b6 Evaluation protocols and results will be documented here.","title":"Evaluations"},{"location":"sections/evaluations/#evaluations","text":"Evaluation protocols and results will be documented here.","title":"Evaluations"},{"location":"sections/papers/","text":"Papers \u00b6 A tabular view of curated papers organized by the reprogrammability taxonomy dimensions. Paper Configuration ($\\lambda$) Location ($\\ell$) Operator ($\\tau$) Alignment ($\\omega$) Venue Adversarial Reprogramming of Neural Networks Elsayed et al. (2019) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) ICLR Adversarial Reprogramming of Text Classification Neural Networks Neekhara et al. (2019) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Statistical (SA) / Linear (LA) EMNLP/IJCNLP Language Models are Few-Shot Learners BROWN et al. (2020) Fixed input-space Concatenative (CO) Identity (ID) NeurIPS Reprogramming Language Models for Molecular Representation Learning Vinod et al. (2020) Learnable Input ($\\mathcal{X}_S$) Parametric (PR) Rule-based (RA) NeurIPS Workshop Learning how to ask: Querying LMs with mixtures of soft prompts Qin et al. (2021) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) NAACL PTR: Prompt Tuning with Rules for Text Classification HAN et al. (2021) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Rule-based (RA) arXiv preprint (cs.CL) Prefix-Tuning: Optimizing Continuous Prompts for Generation Li et al. (2021) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) ACL/IJCNLP The Power of Scale for Parameter-Efficient Prompt Tuning Lester et al. (2021) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Identity (ID) EMNLP Transfer Learning without Knowing: Reprogramming Black-box Machine Learning Models with Scarce Data and Limited Resources Tsai et al. (2021) Learnable input-layers statistical / linear Identity (ID) ICML Voice2series: Reprogramming acoustic models for time series classification Yang et al. (2021) Learnable Input ($\\mathcal{X}_S$) Parametric (PR) Statistical (SA) ICML WARP: Word-level Adversarial ReProgramming Hambardzumyan et al. (2021) Learnable Input ($\\mathcal{X}_S$) Concatenative (CO) Linear (LA) ACL / ACL-IJCNLP Adversarial Reprogramming Revisited Englert et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) NeurIPS An Explanation of In-context Learning as Implicit Bayesian Inference Xie et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICLR Chain-of-Thought Prompting Elicits Reasoning in Large Language Models Wei et al. (2022) Fixed input-space Concatenative (CO) Identity (ID) NeurIPS Conditional Prompt Learning for Vision-Language Models Zhou et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) / Linear (LA) CVPR Cross-modal Adversarial Reprogramming Neekhara et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Linear (LA) WACV Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners ZHANG et al. (2022) Fixed Embedding ($\\mathcal{E}$) Concatenative (CO) Statistical (SA) ICLR Exploring Visual Prompts for Adapting Large-Scale Models Bahng et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) arXiv In-context Learning and Induction Heads OLSSON et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) arXiv Learning To Retrieve Prompts for In-Context Learning Rubin et al. (2022) Fixed input-space Concatenative (CO) Identity (ID) NAACL Learning to Prompt for Vision-Language Models Zhou et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Identity (ID) IJCV Learning to Prompt for Vision-Language Models Zhou et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Linear (LA) IJCV Least-to-Most Prompting Enables Complex Reasoning in Large Language Models Zhou et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICLR P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks Liu et al. (2022) Learnable Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) ACL PPT: Pre-trained Prompt Tuning for Few-shot Learning GU et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Rule-based (RA) ACL Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? MIN et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Rule-based (RA) EMNLP Spot: Better frozen model adaptation through soft prompt transfer Vu et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) ACL Structured Prompting: Scaling In-Context Learning to 1,000 Examples HAO et al. (2022) Fixed Hidden ($\\mathcal{H}$) Concatenative (CO) Identity (ID) arXiv Unleashing the Power of Visual Prompting At the Pixel Level WU et al. (2022) Learnable Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) / Statistical (SA) arXiv Visual Prompt Tuning JIA et al. (2022) Fixed Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) ECCV Visual Prompting via Image Inpainting BAR et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) NeurIPS A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models ALLINGHAM et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICML BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning OH et al. (2023) Learnable input-space Additive (AD) Rule-based (RA) CVPR Decomposed Prompting: A Modular Approach for Solving Complex Tasks Khot et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICLR Deep Graph Reprogramming JING et al. (2023) Learnable Input ($\\mathcal{X}_S$) / Hidden ($\\mathcal{H}$) concatenation / parametric Rule-based (RA) CVPR Explicit Visual Prompting for Low-Level Structure Segmentations Liu et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Parametric (PR) Identity (ID) CVPR From English to More Languages: Parameter-Efficient Model Reprogramming for Cross-Lingual Speech Recognition YANG et al. (2023) Learnable Input ($\\mathcal{X}_S$) / Hidden ($\\mathcal{H}$) Additive (AD) Rule-based (RA) ICASSP InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning Dai et al. (2023) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Identity (ID) / rule / Linear (LA) NeurIPS Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions TRIVEDI et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ACL Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming HUNG et al. (2023) Learnable Input ($\\mathcal{X}_S$) Parametric (PR) Statistical (SA) ICASSP MaPLe: Multi-modal Prompt Learning Khattak et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) CVPR Neural Model Reprogramming with Similarity Based Mapping for Low-Resource Spoken Command Recognition Yen et al. (2023) Learnable input-space Additive (AD) Statistical (SA) Interspeech On the Role of Attention in Prompt-tuning OYMAK et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) ICML PLOT: Prompt Learning with Optimal Transport for Vision-Language Models CHEN et al. (2023) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) ICLR Reprogramming Pretrained Language Models for Antibody Sequence Infilling MELNYK et al. (2023) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Linear (LA) ICML Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V YANG et al. (2023) Fixed Input ($\\mathcal{X}_S$) Additive (AD) Rule-based (RA) arXiv TransHP: Image Classification with Hierarchical Prompting WANG et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) NeurIPS Tuning Multi-mode Token-level Prompt Alignment across Modalities WANG et al. (2023) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) NeurIPS 2023 Understanding and Improving Visual Prompting: A Label-Mapping Perspective CHEN et al. (2023) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) CVPR Universal Prompt Tuning for Graph Neural Networks FANG et al. (2023) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Linear (LA) NeurIPS Visual Instruction Tuning LIU et al. (2023) Learnable Embedding ($\\mathcal{E}$) concatenation / parametric Identity (ID) NeurIPS What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification PRATT et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICCV What Makes Good Examples for Visual In-Context Learning? ZHANG et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) arXiv ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models TIAN et al. (2024) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) CVPR AutoVP: An Automated Visual Prompting Framework and Benchmark TSAO et al. (2024) Learnable Input ($\\mathcal{X}_S$) Concatenative (CO) Statistical (SA) / Linear (LA) ICLR Bayesian-guided Label Mapping for Visual Reprogramming CAI et al. (2024) Learnable input-space Additive (AD) Statistical (SA) NeurIPS Exploring the Transferability of Visual Prompting for Multimodal Large Language Models Zhang et al. (2024) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) CVPR Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models Jiang et al. (2024) Fixed Input ($\\mathcal{X}_S$) / Embedding ($\\mathcal{E}$) addition / concatenation Identity (ID) arXiv Model Reprogramming Outperforms Fine-tuning on Out-of-distribution Data in Text-Image Encoders GENG et al. (2024) Learnable Input ($\\mathcal{X}_S$) / Embedding ($\\mathcal{E}$) addition / parametric Identity (ID) SatML PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs NASIRIANY et al. (2024) Fixed Input ($\\mathcal{X}_S$) Additive (AD) Rule-based (RA) ICML PromptKD: Unsupervised Prompt Distillation for Vision-Language Models LI et al. (2024) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) CVPR Sample-specific Masks for Visual Reprogramming-based Prompting Cai et al. (2024) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) ICML Time-LLM: Time Series Forecasting by Reprogramming Large Language Models JIN et al. (2024) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Linear (LA) ICLR When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations PETROV et al. (2024) Learnable / Fixed Input ($\\mathcal{X}_S$) / Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Identity (ID) ICLR Attribute-based Visual Reprogramming for Vision-Language Models Cai et al. (2025) Learnable Input ($\\mathcal{X}_S$) addition / concatenation Rule-based (RA) ICLR Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want Lin et al. (2025) Learnable embedding-level Parametric (PR) Linear (LA) ICLR Model Reprogramming Demystified: A Neural Tangent Kernel Perspective Chung et al. (2025) Learnable input-layers Additive (AD) Identity (ID) arXiv Refine: Inversion-free backdoor defense via model reprogramming Chen et al. (2025) Learnable input-layers Additive (AD) Identity (ID) ICLR Reprogramming pretrained language models for protein sequence representation learning Vinod et al. (2025) Learnable input-layers Additive (AD) Identity (ID) Digital Discovery Understanding Model Reprogramming for CLIP via Decoupling Visual Prompts CAI et al. (2025) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Linear (LA) ICML","title":"Papers"},{"location":"sections/papers/#papers","text":"A tabular view of curated papers organized by the reprogrammability taxonomy dimensions. Paper Configuration ($\\lambda$) Location ($\\ell$) Operator ($\\tau$) Alignment ($\\omega$) Venue Adversarial Reprogramming of Neural Networks Elsayed et al. (2019) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) ICLR Adversarial Reprogramming of Text Classification Neural Networks Neekhara et al. (2019) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Statistical (SA) / Linear (LA) EMNLP/IJCNLP Language Models are Few-Shot Learners BROWN et al. (2020) Fixed input-space Concatenative (CO) Identity (ID) NeurIPS Reprogramming Language Models for Molecular Representation Learning Vinod et al. (2020) Learnable Input ($\\mathcal{X}_S$) Parametric (PR) Rule-based (RA) NeurIPS Workshop Learning how to ask: Querying LMs with mixtures of soft prompts Qin et al. (2021) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) NAACL PTR: Prompt Tuning with Rules for Text Classification HAN et al. (2021) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Rule-based (RA) arXiv preprint (cs.CL) Prefix-Tuning: Optimizing Continuous Prompts for Generation Li et al. (2021) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) ACL/IJCNLP The Power of Scale for Parameter-Efficient Prompt Tuning Lester et al. (2021) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Identity (ID) EMNLP Transfer Learning without Knowing: Reprogramming Black-box Machine Learning Models with Scarce Data and Limited Resources Tsai et al. (2021) Learnable input-layers statistical / linear Identity (ID) ICML Voice2series: Reprogramming acoustic models for time series classification Yang et al. (2021) Learnable Input ($\\mathcal{X}_S$) Parametric (PR) Statistical (SA) ICML WARP: Word-level Adversarial ReProgramming Hambardzumyan et al. (2021) Learnable Input ($\\mathcal{X}_S$) Concatenative (CO) Linear (LA) ACL / ACL-IJCNLP Adversarial Reprogramming Revisited Englert et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) NeurIPS An Explanation of In-context Learning as Implicit Bayesian Inference Xie et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICLR Chain-of-Thought Prompting Elicits Reasoning in Large Language Models Wei et al. (2022) Fixed input-space Concatenative (CO) Identity (ID) NeurIPS Conditional Prompt Learning for Vision-Language Models Zhou et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) / Linear (LA) CVPR Cross-modal Adversarial Reprogramming Neekhara et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Linear (LA) WACV Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners ZHANG et al. (2022) Fixed Embedding ($\\mathcal{E}$) Concatenative (CO) Statistical (SA) ICLR Exploring Visual Prompts for Adapting Large-Scale Models Bahng et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) arXiv In-context Learning and Induction Heads OLSSON et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) arXiv Learning To Retrieve Prompts for In-Context Learning Rubin et al. (2022) Fixed input-space Concatenative (CO) Identity (ID) NAACL Learning to Prompt for Vision-Language Models Zhou et al. (2022) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Identity (ID) IJCV Learning to Prompt for Vision-Language Models Zhou et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Linear (LA) IJCV Least-to-Most Prompting Enables Complex Reasoning in Large Language Models Zhou et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICLR P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks Liu et al. (2022) Learnable Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) ACL PPT: Pre-trained Prompt Tuning for Few-shot Learning GU et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Rule-based (RA) ACL Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? MIN et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Rule-based (RA) EMNLP Spot: Better frozen model adaptation through soft prompt transfer Vu et al. (2022) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) ACL Structured Prompting: Scaling In-Context Learning to 1,000 Examples HAO et al. (2022) Fixed Hidden ($\\mathcal{H}$) Concatenative (CO) Identity (ID) arXiv Unleashing the Power of Visual Prompting At the Pixel Level WU et al. (2022) Learnable Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) / Statistical (SA) arXiv Visual Prompt Tuning JIA et al. (2022) Fixed Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) ECCV Visual Prompting via Image Inpainting BAR et al. (2022) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) NeurIPS A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models ALLINGHAM et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICML BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning OH et al. (2023) Learnable input-space Additive (AD) Rule-based (RA) CVPR Decomposed Prompting: A Modular Approach for Solving Complex Tasks Khot et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICLR Deep Graph Reprogramming JING et al. (2023) Learnable Input ($\\mathcal{X}_S$) / Hidden ($\\mathcal{H}$) concatenation / parametric Rule-based (RA) CVPR Explicit Visual Prompting for Low-Level Structure Segmentations Liu et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Parametric (PR) Identity (ID) CVPR From English to More Languages: Parameter-Efficient Model Reprogramming for Cross-Lingual Speech Recognition YANG et al. (2023) Learnable Input ($\\mathcal{X}_S$) / Hidden ($\\mathcal{H}$) Additive (AD) Rule-based (RA) ICASSP InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning Dai et al. (2023) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Identity (ID) / rule / Linear (LA) NeurIPS Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions TRIVEDI et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ACL Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming HUNG et al. (2023) Learnable Input ($\\mathcal{X}_S$) Parametric (PR) Statistical (SA) ICASSP MaPLe: Multi-modal Prompt Learning Khattak et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) CVPR Neural Model Reprogramming with Similarity Based Mapping for Low-Resource Spoken Command Recognition Yen et al. (2023) Learnable input-space Additive (AD) Statistical (SA) Interspeech On the Role of Attention in Prompt-tuning OYMAK et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) ICML PLOT: Prompt Learning with Optimal Transport for Vision-Language Models CHEN et al. (2023) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) ICLR Reprogramming Pretrained Language Models for Antibody Sequence Infilling MELNYK et al. (2023) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Linear (LA) ICML Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V YANG et al. (2023) Fixed Input ($\\mathcal{X}_S$) Additive (AD) Rule-based (RA) arXiv TransHP: Image Classification with Hierarchical Prompting WANG et al. (2023) Learnable Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Linear (LA) NeurIPS Tuning Multi-mode Token-level Prompt Alignment across Modalities WANG et al. (2023) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) NeurIPS 2023 Understanding and Improving Visual Prompting: A Label-Mapping Perspective CHEN et al. (2023) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) CVPR Universal Prompt Tuning for Graph Neural Networks FANG et al. (2023) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Linear (LA) NeurIPS Visual Instruction Tuning LIU et al. (2023) Learnable Embedding ($\\mathcal{E}$) concatenation / parametric Identity (ID) NeurIPS What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification PRATT et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) ICCV What Makes Good Examples for Visual In-Context Learning? ZHANG et al. (2023) Fixed Input ($\\mathcal{X}_S$) Concatenative (CO) Identity (ID) arXiv ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models TIAN et al. (2024) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) CVPR AutoVP: An Automated Visual Prompting Framework and Benchmark TSAO et al. (2024) Learnable Input ($\\mathcal{X}_S$) Concatenative (CO) Statistical (SA) / Linear (LA) ICLR Bayesian-guided Label Mapping for Visual Reprogramming CAI et al. (2024) Learnable input-space Additive (AD) Statistical (SA) NeurIPS Exploring the Transferability of Visual Prompting for Multimodal Large Language Models Zhang et al. (2024) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) CVPR Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models Jiang et al. (2024) Fixed Input ($\\mathcal{X}_S$) / Embedding ($\\mathcal{E}$) addition / concatenation Identity (ID) arXiv Model Reprogramming Outperforms Fine-tuning on Out-of-distribution Data in Text-Image Encoders GENG et al. (2024) Learnable Input ($\\mathcal{X}_S$) / Embedding ($\\mathcal{E}$) addition / parametric Identity (ID) SatML PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs NASIRIANY et al. (2024) Fixed Input ($\\mathcal{X}_S$) Additive (AD) Rule-based (RA) ICML PromptKD: Unsupervised Prompt Distillation for Vision-Language Models LI et al. (2024) Learnable Embedding ($\\mathcal{E}$) Concatenative (CO) Identity (ID) CVPR Sample-specific Masks for Visual Reprogramming-based Prompting Cai et al. (2024) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Statistical (SA) ICML Time-LLM: Time Series Forecasting by Reprogramming Large Language Models JIN et al. (2024) Learnable Embedding ($\\mathcal{E}$) Parametric (PR) Linear (LA) ICLR When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations PETROV et al. (2024) Learnable / Fixed Input ($\\mathcal{X}_S$) / Embedding ($\\mathcal{E}$) / Hidden ($\\mathcal{H}$) Concatenative (CO) Identity (ID) ICLR Attribute-based Visual Reprogramming for Vision-Language Models Cai et al. (2025) Learnable Input ($\\mathcal{X}_S$) addition / concatenation Rule-based (RA) ICLR Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want Lin et al. (2025) Learnable embedding-level Parametric (PR) Linear (LA) ICLR Model Reprogramming Demystified: A Neural Tangent Kernel Perspective Chung et al. (2025) Learnable input-layers Additive (AD) Identity (ID) arXiv Refine: Inversion-free backdoor defense via model reprogramming Chen et al. (2025) Learnable input-layers Additive (AD) Identity (ID) ICLR Reprogramming pretrained language models for protein sequence representation learning Vinod et al. (2025) Learnable input-layers Additive (AD) Identity (ID) Digital Discovery Understanding Model Reprogramming for CLIP via Decoupling Visual Prompts CAI et al. (2025) Learnable Input ($\\mathcal{X}_S$) Additive (AD) Linear (LA) ICML","title":"Papers"},{"location":"sections/taxonomy/","text":"Taxonomy \u00b6 This page mirrors meta/taxonomy.md . Neural Network Reprogrammability Taxonomy \u00b6 This taxonomy organizes neural network reprogrammability methods across four key dimensions, based on the comprehensive survey \"A Comprehensive Survey of Neural Network Reprogrammability\". Four-Dimensional Taxonomy \u00b6 1. Configuration ($\\lambda$) - Format of Reprogramming Parameters \u00b6 Learnable : Parameters that are learned during adaptation - Model reprogramming approaches that learn input transformations - Adversarial reprogramming with learnable perturbations - Prompt tuning with trainable continuous prompts - Soft prompts with optimizable embeddings Fixed : Parameters that are manually designed or rule-based - Hard prompts using fixed text templates - Instruction-based approaches with predefined formats - Manual prompt engineering Both (Fixed & Learnable) : Hybrid approaches combining both types - Methods that use both fixed templates and learnable components 2. Location ($\\ell$) - Where Modifications are Applied \u00b6 Input ($\\mathcal{X}_S$) : Modifications at the input layer - Input space transformations - Adversarial reprogramming perturbations - Input-level prompt prepending Hidden ($\\mathcal{H}$) : Modifications within intermediate layers - Hidden layer adaptations - Intermediate feature transformations - Cross-attention mechanisms Embedding ($\\mathcal{E}$) : Modifications at the embedding layer - Token embedding adjustments - Positional embedding modifications - Embedding space transformations Output ($\\mathcal{Y}$) : Modifications at the output layer - Output head replacements - Final layer adaptations 3. Operator ($\\tau$) - Type of Transformation Applied \u00b6 Additive (AD) : Adding new parameters or features - Prompt token addition - Residual-style modifications Concatenative (CO) : Combining features from different sources - Input concatenation with learned transformations - Feature fusion approaches Parametric (PR) : Complex learned transformations - Non-linear mappings - Learned parameter updates Replacement (RE) : Substituting components - Component swapping - Module replacement 4. Alignment ($\\omega$) - How Target Tasks Align with Source Tasks \u00b6 Linear (LA) : Linear relationship between source and target - Direct feature mappings - Linear transformations Statistical (SA) : Statistical alignment approaches - Distribution matching - Statistical feature alignment Rule-based (RA) : Rule-driven alignment - Template-based approaches - Structured rule-based mapping Identity (ID) : Theoretical or identity-based alignment - Theoretical frameworks - Identity-preserving transformations Method Categories \u00b6 Note that this is a rough categorization for the existing studies. Model Reprogramming \u00b6 Configuration : Typically Learnable Location : Usually Input ($\\mathcal{X}_S$) or Embedding ($\\mathcal{E}$) Operator : Commonly Concatenative (CO) or Additive (AD) or Parametric (PR) Alignment : Primarily Linear (LA) or Statistical (SA) Prompt Tuning \u00b6 Configuration : Learnable Location : Embedding ($\\mathcal{E}$) or Hidden ($\\mathcal{H}$) Operator : Commonly Concatenative (CO) or Parametric (PR) Alignment : Linear (LA) or Rule-based (RA) or Identity Mapping (ID) Prompt Instruction \u00b6 Configuration : Fixed Location : Input ($\\mathcal{X}_S$) Operator : Commonly Concatenative (CO) or Additive (AD) or Parametric (PR) Alignment : Rule-based (RA) or Identity Mapping (ID) Common Evaluation Scenarios \u00b6 Under construction ... Usage in Papers Table \u00b6 The papers table in docs/sections/papers.md uses this taxonomy to classify each paper across all four dimensions, providing a comprehensive view of the reprogrammability landscape.","title":"Taxonomy"},{"location":"sections/taxonomy/#taxonomy","text":"This page mirrors meta/taxonomy.md .","title":"Taxonomy"},{"location":"sections/taxonomy/#neural-network-reprogrammability-taxonomy","text":"This taxonomy organizes neural network reprogrammability methods across four key dimensions, based on the comprehensive survey \"A Comprehensive Survey of Neural Network Reprogrammability\".","title":"Neural Network Reprogrammability Taxonomy"},{"location":"sections/taxonomy/#four-dimensional-taxonomy","text":"","title":"Four-Dimensional Taxonomy"},{"location":"sections/taxonomy/#1-configuration-lambda-format-of-reprogramming-parameters","text":"Learnable : Parameters that are learned during adaptation - Model reprogramming approaches that learn input transformations - Adversarial reprogramming with learnable perturbations - Prompt tuning with trainable continuous prompts - Soft prompts with optimizable embeddings Fixed : Parameters that are manually designed or rule-based - Hard prompts using fixed text templates - Instruction-based approaches with predefined formats - Manual prompt engineering Both (Fixed & Learnable) : Hybrid approaches combining both types - Methods that use both fixed templates and learnable components","title":"1. Configuration ($\\lambda$) - Format of Reprogramming Parameters"},{"location":"sections/taxonomy/#2-location-ell-where-modifications-are-applied","text":"Input ($\\mathcal{X}_S$) : Modifications at the input layer - Input space transformations - Adversarial reprogramming perturbations - Input-level prompt prepending Hidden ($\\mathcal{H}$) : Modifications within intermediate layers - Hidden layer adaptations - Intermediate feature transformations - Cross-attention mechanisms Embedding ($\\mathcal{E}$) : Modifications at the embedding layer - Token embedding adjustments - Positional embedding modifications - Embedding space transformations Output ($\\mathcal{Y}$) : Modifications at the output layer - Output head replacements - Final layer adaptations","title":"2. Location ($\\ell$) - Where Modifications are Applied"},{"location":"sections/taxonomy/#3-operator-tau-type-of-transformation-applied","text":"Additive (AD) : Adding new parameters or features - Prompt token addition - Residual-style modifications Concatenative (CO) : Combining features from different sources - Input concatenation with learned transformations - Feature fusion approaches Parametric (PR) : Complex learned transformations - Non-linear mappings - Learned parameter updates Replacement (RE) : Substituting components - Component swapping - Module replacement","title":"3. Operator ($\\tau$) - Type of Transformation Applied"},{"location":"sections/taxonomy/#4-alignment-omega-how-target-tasks-align-with-source-tasks","text":"Linear (LA) : Linear relationship between source and target - Direct feature mappings - Linear transformations Statistical (SA) : Statistical alignment approaches - Distribution matching - Statistical feature alignment Rule-based (RA) : Rule-driven alignment - Template-based approaches - Structured rule-based mapping Identity (ID) : Theoretical or identity-based alignment - Theoretical frameworks - Identity-preserving transformations","title":"4. Alignment ($\\omega$) - How Target Tasks Align with Source Tasks"},{"location":"sections/taxonomy/#method-categories","text":"Note that this is a rough categorization for the existing studies.","title":"Method Categories"},{"location":"sections/taxonomy/#model-reprogramming","text":"Configuration : Typically Learnable Location : Usually Input ($\\mathcal{X}_S$) or Embedding ($\\mathcal{E}$) Operator : Commonly Concatenative (CO) or Additive (AD) or Parametric (PR) Alignment : Primarily Linear (LA) or Statistical (SA)","title":"Model Reprogramming"},{"location":"sections/taxonomy/#prompt-tuning","text":"Configuration : Learnable Location : Embedding ($\\mathcal{E}$) or Hidden ($\\mathcal{H}$) Operator : Commonly Concatenative (CO) or Parametric (PR) Alignment : Linear (LA) or Rule-based (RA) or Identity Mapping (ID)","title":"Prompt Tuning"},{"location":"sections/taxonomy/#prompt-instruction","text":"Configuration : Fixed Location : Input ($\\mathcal{X}_S$) Operator : Commonly Concatenative (CO) or Additive (AD) or Parametric (PR) Alignment : Rule-based (RA) or Identity Mapping (ID)","title":"Prompt Instruction"},{"location":"sections/taxonomy/#common-evaluation-scenarios","text":"Under construction ...","title":"Common Evaluation Scenarios"},{"location":"sections/taxonomy/#usage-in-papers-table","text":"The papers table in docs/sections/papers.md uses this taxonomy to classify each paper across all four dimensions, providing a comprehensive view of the reprogrammability landscape.","title":"Usage in Papers Table"}]}