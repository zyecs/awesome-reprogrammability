# Papers

A tabular view of curated papers organized by the reprogrammability taxonomy dimensions.

Paper | Configuration ($\lambda$) | Location ($\ell$) | Operator ($\tau$) | Alignment ($\omega$) | Venue
--- | --- | --- | --- | --- | ---
[Adversarial Reprogramming of Neural Networks](https://arxiv.org/abs/1806.11146) Elsayed et al. (2019) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Statistical (SA) | ICLR
[Adversarial Reprogramming of Text Classification Neural Networks](https://arxiv.org/abs/1809.01829) Neekhara et al. (2019) | Learnable | Embedding ($\mathcal{E}$) | Parametric (PR) | Statistical (SA) / Linear (LA) | EMNLP/IJCNLP
[Reprogramming Language Models for Molecular Representation Learning](https://arxiv.org/abs/2012.03460) Vinod et al. (2020) | Learnable | Input ($\mathcal{X}_S$) | Parametric (PR) | Rule-based (RA) | NeurIPS Workshop
[Learning how to ask: Querying LMs with mixtures of soft prompts](https://arxiv.org/abs/2104.06599) Qin et al. (2021) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | NAACL
[PTR: Prompt Tuning with Rules for Text Classification](https://arxiv.org/abs/2105.11259) HAN et al. (2021) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Rule-based (RA) | arXiv preprint (cs.CL)
[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/abs/2101.00190) Li et al. (2021) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | ACL/IJCNLP
[The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/abs/2104.08691) Lester et al. (2021) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Identity (ID) | EMNLP
[Transfer Learning without Knowing: Reprogramming Black-box Machine Learning Models with Scarce Data and Limited Resources](https://arxiv.org/abs/2007.08714) Tsai et al. (2021) | Learnable | input-layers | statistical / linear | Identity (ID) | ICML
[Voice2series: Reprogramming acoustic models for time series classification](https://arxiv.org/abs/2106.09296) Yang et al. (2021) | Learnable | Input ($\mathcal{X}_S$) | Parametric (PR) | Statistical (SA) | ICML
[WARP: Word-level Adversarial ReProgramming](https://arxiv.org/abs/2101.00121) Hambardzumyan et al. (2021) | Learnable | Input ($\mathcal{X}_S$) | Concatenative (CO) | Linear (LA) | ACL / ACL-IJCNLP
[Adversarial Reprogramming Revisited](https://arxiv.org/abs/2206.03466) Englert et al. (2022) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Statistical (SA) | NeurIPS
[An Explanation of In-context Learning as Implicit Bayesian Inference](https://arxiv.org/abs/2111.02080) Xie et al. (2022) | Learnable | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | ICLR
[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) Wei et al. (2022) | Fixed | input-space | Concatenative (CO) | Identity (ID) | NeurIPS
[Conditional Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2203.05557) Zhou et al. (2022) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) / Linear (LA) | CVPR
[Cross-modal Adversarial Reprogramming](https://arxiv.org/abs/2102.07325) Neekhara et al. (2022) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Linear (LA) | WACV
[Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners](https://arxiv.org/abs/2108.13161) ZHANG et al. (2022) | Fixed | Embedding ($\mathcal{E}$) | Concatenative (CO) | Statistical (SA) | ICLR
[Exploring Visual Prompts for Adapting Large-Scale Models](https://arxiv.org/abs/2203.17274) Bahng et al. (2022) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Statistical (SA) | arXiv
[In-context Learning and Induction Heads](https://arxiv.org/abs/2209.11895) OLSSON et al. (2022) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | arXiv
[Learning To Retrieve Prompts for In-Context Learning](https://arxiv.org/abs/2112.08633) Rubin et al. (2022) | Learnable | input-space | Concatenative (CO) | Identity (ID) | NAACL
[Learning to Prompt for Vision-Language Models](https://arxiv.org/abs/2109.01134) Zhou et al. (2022) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Identity (ID) | IJCV
[Learning to Prompt for Vision-Language Models](https://arxiv.org/abs/2109.01134) Zhou et al. (2022) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Linear (LA) | IJCV
[Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/abs/2205.10625) Zhou et al. (2022) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | ICLR
[Multitask Prompted Training Enables Zero-Shot Task Generalization](https://arxiv.org/abs/2110.08207) SANH et al. (2022) | Learnable | X^S | Concatenative (CO) | Identity (ID) | ICLR 2022 (Spotlight) :contentReference[oaicite:0]{index=0}
[P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks](https://arxiv.org/abs/2110.07602) Liu et al. (2022) | Learnable | Hidden ($\mathcal{H}$) | Concatenative (CO) | Linear (LA) | ACL
[PPT: Pre-trained Prompt Tuning for Few-shot Learning](https://arxiv.org/abs/2109.04332) GU et al. (2022) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Rule-based (RA) | ACL
[Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?](https://arxiv.org/abs/2202.12837) MIN et al. (2022) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Rule-based (RA) | EMNLP
[Spot: Better frozen model adaptation through soft prompt transfer](https://arxiv.org/abs/2110.07904) Vu et al. (2022) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | ACL
[Structured Prompting: Scaling In-Context Learning to 1,000 Examples](https://arxiv.org/abs/2212.06713) HAO et al. (2022) | Fixed | Hidden ($\mathcal{H}$) | Concatenative (CO) | Identity (ID) | arXiv
[Unleashing the Power of Visual Prompting At the Pixel Level](https://arxiv.org/abs/2212.10556) WU et al. (2022) | Learnable | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) / Statistical (SA) | arXiv
[Visual Prompt Tuning](https://arxiv.org/abs/2203.12119) JIA et al. (2022) | Fixed | Embedding ($\mathcal{E}$) / Hidden ($\mathcal{H}$) | Concatenative (CO) | Linear (LA) | ECCV
[Visual Prompting via Image Inpainting](https://arxiv.org/abs/2209.00647) BAR et al. (2022) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | NeurIPS
[A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models](https://arxiv.org/abs/2302.06235) ALLINGHAM et al. (2023) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | ICML
[BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning](https://arxiv.org/abs/2303.14773) OH et al. (2023) | Learnable | input-space | Additive (AD) | Rule-based (RA) | CVPR
[Decomposed Prompting: A Modular Approach for Solving Complex Tasks](https://arxiv.org/abs/2210.02406) Khot et al. (2023) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | ICLR
[Deep Graph Reprogramming](https://arxiv.org/abs/2304.14593) JING et al. (2023) | Learnable | Input ($\mathcal{X}_S$) / Hidden ($\mathcal{H}$) | concatenation / parametric | Rule-based (RA) | CVPR
[Explicit Visual Prompting for Low-Level Structure Segmentations](https://arxiv.org/abs/2303.10883) Liu et al. (2023) | Learnable | Embedding ($\mathcal{E}$) / Hidden ($\mathcal{H}$) | Parametric (PR) | Identity (ID) | CVPR
[From English to More Languages: Parameter-Efficient Model Reprogramming for Cross-Lingual Speech Recognition](https://arxiv.org/abs/2301.07851) YANG et al. (2023) | Learnable | Input ($\mathcal{X}_S$) / Hidden ($\mathcal{H}$) | Additive (AD) | Rule-based (RA) | ICASSP
[InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/abs/2305.06500) Dai et al. (2023) | Learnable | Embedding ($\mathcal{E}$) | Parametric (PR) | Identity (ID) / rule / Linear (LA) | NeurIPS
[Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions](https://arxiv.org/abs/2212.10509) TRIVEDI et al. (2023) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | ACL
[Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming](https://arxiv.org/abs/2211.01317) HUNG et al. (2023) | Learnable | X^S | param | Identity (ID) | ICASSP
[MaPLe: Multi-modal Prompt Learning](https://arxiv.org/abs/2210.03117) Khattak et al. (2023) | Learnable | Embedding ($\mathcal{E}$) / Hidden ($\mathcal{H}$) | Concatenative (CO) | Linear (LA) | CVPR
[Neural Model Reprogramming with Similarity Based Mapping for Low-Resource Spoken Command Recognition](https://arxiv.org/abs/2110.03894) Yen et al. (2023) | Learnable | input-space | Additive (AD) | Statistical (SA) | Interspeech
[On the Role of Attention in Prompt-tuning](https://arxiv.org/abs/2306.03435) OYMAK et al. (2023) | Learnable | Embedding ($\mathcal{E}$) / Hidden ($\mathcal{H}$) | Concatenative (CO) | Linear (LA) | ICML 2023
[PLOT: Prompt Learning with Optimal Transport for Vision-Language Models](https://arxiv.org/abs/2210.01253) CHEN et al. (2023) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | ICLR
[Reprogramming Pretrained Language Models for Antibody Sequence Infilling](https://arxiv.org/abs/2210.07144) MELNYK et al. (2023) | Learnable | Embedding ($\mathcal{E}$) | Parametric (PR) | Linear (LA) | ICML
[Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V](https://arxiv.org/abs/2310.11441) YANG et al. (2023) | Fixed | Input ($\mathcal{X}_S$) | Additive (AD) | Rule-based (RA) | arXiv
[TransHP: Image Classification with Hierarchical Prompting](https://arxiv.org/abs/2304.06385) WANG et al. (2023) | Learnable | Embedding ($\mathcal{E}$) / Hidden ($\mathcal{H}$) | Concatenative (CO) | Linear (LA) | NeurIPS
[Tuning Multi-mode Token-level Prompt Alignment across Modalities](https://arxiv.org/abs/2309.13847) WANG et al. (2023) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | NeurIPS 2023
[Understanding and Improving Visual Prompting: A Label-Mapping Perspective](https://arxiv.org/abs/2211.11635) CHEN et al. (2023) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Statistical (SA) | CVPR
[Universal Prompt Tuning for Graph Neural Networks](https://arxiv.org/abs/2209.15240) FANG et al. (2023) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Linear (LA) | NeurIPS
[Visual Instruction Tuning](https://arxiv.org/abs/2304.08485) LIU et al. (2023) | Learnable | Embedding ($\mathcal{E}$) | concatenation / parametric | Identity (ID) | NeurIPS
[What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification](https://arxiv.org/abs/2209.03320) PRATT et al. (2023) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | ICCV
[What Makes Good Examples for Visual In-Context Learning?](https://arxiv.org/abs/2301.13670) ZHANG et al. (2023) | Fixed | Input ($\mathcal{X}_S$) | Concatenative (CO) | Identity (ID) | arXiv
[ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2311.16494) TIAN et al. (2024) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | CVPR
[AutoVP: An Automated Visual Prompting Framework and Benchmark](https://arxiv.org/abs/2310.08381) TSAO et al. (2024) | Learnable | Input ($\mathcal{X}_S$) | Concatenative (CO) | Statistical (SA) / Linear (LA) | ICLR
[Bayesian-guided Label Mapping for Visual Reprogramming](https://arxiv.org/abs/2410.24018) CAI et al. (2024) | Learnable | input-space | Additive (AD) | Statistical (SA) | NeurIPS
[Exploring the Transferability of Visual Prompting for Multimodal Large Language Models](https://arxiv.org/abs/2404.11207) Zhang et al. (2024) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Statistical (SA) | CVPR
[Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models](https://arxiv.org/abs/2404.04514) Jiang et al. (2024) | Fixed | Input ($\mathcal{X}_S$) / Embedding ($\mathcal{E}$) | addition / concatenation | Identity (ID) | arXiv
[Model Reprogramming Outperforms Fine-tuning on Out-of-distribution Data in Text-Image Encoders](https://arxiv.org/abs/2403.10800) GENG et al. (2024) | Learnable | Input ($\mathcal{X}_S$) / Embedding ($\mathcal{E}$) | addition / parametric | Identity (ID) | SatML
[PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs](https://arxiv.org/abs/2402.07872) NASIRIANY et al. (2024) | Fixed | Input ($\mathcal{X}_S$) | Additive (AD) | Rule-based (RA) | ICML
[PromptKD: Unsupervised Prompt Distillation for Vision-Language Models](https://arxiv.org/abs/2403.02781) LI et al. (2024) | Learnable | Embedding ($\mathcal{E}$) | Concatenative (CO) | Identity (ID) | CVPR
[Sample-specific Masks for Visual Reprogramming-based Prompting](https://arxiv.org/abs/2406.03150) Cai et al. (2024) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Statistical (SA) | ICML
[Time-LLM: Time Series Forecasting by Reprogramming Large Language Models](https://arxiv.org/abs/2310.01728) JIN et al. (2024) | Learnable | Embedding ($\mathcal{E}$) | Parametric (PR) | Linear (LA) | ICLR
[When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations](https://arxiv.org/pdf/2310.19698) PETROV et al. (2024) | Learnable | Input ($\mathcal{X}_S$) / Embedding ($\mathcal{E}$) / Hidden ($\mathcal{H}$) | Concatenative (CO) | Identity (ID) | ICLR
[Attribute-based Visual Reprogramming for Vision-Language Models](https://arxiv.org/abs/2501.13982) Cai et al. (2025) | Learnable | Input ($\mathcal{X}_S$) | addition / concatenation | Rule-based (RA) | ICLR
[Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want](https://arxiv.org/abs/2403.20271) Lin et al. (2025) | Learnable | embedding-level | Parametric (PR) | Linear (LA) | ICLR
[Model Reprogramming Demystified: A Neural Tangent Kernel Perspective](https://arxiv.org/abs/2506.0620) Chung et al. (2025) | Learnable | input-layers | Additive (AD) | Identity (ID) | arXiv
[Refine: Inversion-free backdoor defense via model reprogramming](https://arxiv.org/abs/2502.18508) Chen et al. (2025) | Learnable | input-layers | Additive (AD) | Identity (ID) | ICLR
[Reprogramming pretrained language models for protein sequence representation learning](https://arxiv.org/abs/2301.02120) Vinod et al. (2025) | Learnable | input-layers | Additive (AD) | Identity (ID) | Digital Discovery
[Understanding Model Reprogramming for CLIP via Decoupling Visual Prompts](https://arxiv.org/abs/2506.01000) CAI et al. (2025) | Learnable | Input ($\mathcal{X}_S$) | Additive (AD) | Linear (LA) | ICML 2025
