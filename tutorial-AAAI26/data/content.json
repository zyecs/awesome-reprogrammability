{
  "tutorial": {
    "title": "Neural Network Reprogrammability: A Unified Framework for Parameter-Efficient Foundation Model Adaptation",
    "conference": "AAAI 2026",
    "date": "2:00 PM, January 21, 2026",
    "duration": "3.5 hours",
    "venue": "Room Peridot 205, SINGAPORE EXPO, Singapore",
    "contact": [
      {
        "name": "Feng Liu",
        "email": "feng.liu1@unimelb.edu.au",
        "homepage": "https://fengliu90.github.io/"
      },
      {
        "name": "Zesheng Ye",
        "email": "zesheng.ye@unimelb.edu.au",
        "homepage": "https://zyecs.github.io"
      }
    ],
    "official_link": "https://aaai.org/conference/aaai/aaai-26/",
    "description": "Welcome to the tutorial on <strong>Neural Network Reprogrammability</strong>. We'll cover <em>theoretical foundations</em>, <em>practical implementation</em>, and <em>trustworthiness implications</em>.\n\nJoin us and learn how to adapt frozen pre-trained models for new tasks with <strong>input transformation</strong> and <strong>output alignment</strong>!"
  },
  "sessions": [
    {
      "order": 1,
      "title": "Foundations of Reprogrammability",
      "presenter": "Feng Liu",
      "duration": "70 min (60 min lecture + 10 min Q&A)",
      "topics": [
        "This session establishes the <strong>WHY</strong> and <strong>WHAT</strong> of the neural network reprogrammability framework.",
        "Adaptation bottleneck and paradigm shift from fully fine-tuning to parameter-efficient fine-tuning",
        "From vulnerability to strength: leveraging input sensitivity positively for model adaptation",
        "Examples of reprogrammability: in-context learning vs model reprogramming",
        "Definition of reprogrammability across modalities and architectures."
      ]
    },
    {
      "order": 2,
      "title": "Mechanics of Reprogrammability",
      "presenter": "Zesheng Ye",
      "duration": "70 min (60 min lecture + 10 min Q&A)",
      "topics": [
        "This session introduces the <strong>HOW</strong> of the neural network reprogrammability framework.",
        "Comprehensive taxonomy of Input Manipulation.",
        "Comprehensive taxonomy of Ouput Alignment.",
        "Deep dive case study: sample-specific input manipulation and probabilistic output alignment",
        "Hands-on implementation examples"
      ]
    },
    {
      "order": 3,
      "title": "Implications of Reprogrammability",
      "presenter": "Pin-Yu Chen",
      "duration": "70 min (60 min lecture + 10 min Q&A)",
      "topics": [
        "This session discusses the <strong>SO WHAT</strong> of the neural network reprogrammability framework.",
        "Holistic trustworthiness evaluation: robustness, security, fairness perspectives",
        "Real-world applications: bioinformatics, time series analysis, multimodal learning",
        "Emerging challenges: adversarial reprogramming, reprogramming against backdoor attacks, privacy implications",
        "Future research directions and open challenges in the field"
      ]
    }
  ],
  "speakers": [
    {
      "name": "Feng Liu",
      "affiliation": "The University of Melbourne; RIKEN AIP",
      "email": "feng.liu1@unimelb.edu.au",
      "bio": "Dr. Feng Liu is a Senior Lecturer in Machine Learning and ARC DECRA Fellow at The University of Melbourne, where he directs the Trustworthy Machine Learning and Reasoning Lab. He is also a Visiting Scientist at RIKEN AIP. His research focuses on hypothesis testing and trustworthy machine learning. He has served as an area chair for ICML, NeurIPS, ICLR, and AISTATS, and as an editor or action editor for several leading journals. His work has been recognized with the NeurIPS 2022 Outstanding Paper Award and multiple Outstanding Reviewer Awards.",
      "sessions": [
        1
      ]
    },
    {
      "name": "Zesheng Ye",
      "affiliation": "The University of Melbourne",
      "email": "zesheng.ye@unimelb.edu.au",
      "bio": "Dr. Zesheng Ye is a Postdoctoral Research Fellow at The University of Melbourne and a recipient of the NIPG Fellowship, working on trustworthy machine learning, with a focus on the robustness, efficiency, privacy of Foundation Model deployment. He received his Ph.D. from the University of New South Wales and serves as Area Chair/Senior PC Member for conferences including TheWebConf, ICASSP, CIKM, and IJCNN. He is also a regular reviewer for ICML, NeurIPS, ICLR, AAAI, and CVPR, and has been recognized with the PRCV 2024 Best Reviewer Award, ICML 2025 Top Reviewer Award, and RecSys 2025 Distinguished PC Member Award.",
      "sessions": [
        2
      ]
    },
    {
      "name": "Pin-Yu Chen",
      "affiliation": "IBM Research AI; MIT-IBM Watson AI Lab",
      "email": "pin-yu.chen@ibm.com",
      "bio": "Dr. Pin-Yu Chen is a Principal Research Scientist at the IBM Thomas J. Watson Research Center and Chief Scientist of the RPI-IBM AI Research Collaboration. His research focuses on trustworthy machine learning, with emphasis on AI safety and robustness. He is a co-author of Adversarial Robustness for Machine Learning and recipient of the 2023 IJCAI Computers and Thought Award. Dr. Chen has published widely at top AI/ML conferences, given tutorials at NeurIPS, AAAI, CVPR, and others, and serves as area chair for major venues. He is an IEEE Fellow, ACM Distinguished Lecturer, and IBM Master Inventor.",
      "sessions": [
        3
      ]
    }
  ],
  "materials": {
    "slides": [
      {
        "title": "Session 1: Foundations of Reprogrammability",
        "url": "TBD",
        "format": "PDF",
        "description": "Theoretical foundations and formal framework"
      },
      {
        "title": "Session 2: Input Manipulation Mechanics",
        "url": "TBD",
        "format": "PDF",
        "description": "Practical implementation and taxonomy"
      },
      {
        "title": "Session 3: Trustworthy AI Implications",
        "url": "TBD",
        "format": "PDF",
        "description": "Security, robustness, and applications"
      }
    ],
    "videos": [
      {
        "title": "Full Tutorial Recording",
        "url": "TBD",
        "platform": "YouTube",
        "description": "Complete 3.5-hour tutorial recording"
      },
      {
        "title": "Session Highlights",
        "url": "TBD",
        "platform": "YouTube",
        "description": "Key takeaways and demonstrations"
      }
    ],
    "code": [
      {
        "title": "Tutorial Implementation Examples",
        "url": "TBD",
        "description": "Code examples for all three reprogramming paradigms"
      },
      {
        "title": "Interactive Jupyter Notebooks",
        "url": "TBD",
        "description": "Hands-on exercises and demonstrations"
      },
      {
        "title": "Framework Integration Guide",
        "url": "TBD",
        "description": "PyTorch and TensorFlow implementation guides"
      }
    ]
  },
  "reading": [
    {
      "title": "Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction",
      "authors": "Ye, Z., Cai, C., Dong, R., Feng, L., Qi, J., Chen, P.-Y., Liu, F.",
      "url": "https://arxiv.org/abs/2506.04650",
      "type": "survey",
      "description": "Introducing the unified reprogrammability framework",
      "bibtex": "@article{ye2025neural,\n  title={Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction},\n  author={Ye, Zesheng and Cai, Chengyi and Dong, Ruijiang and Qi, Jianzhong and Feng, Lei and Chen, Pin-Yu and Liu, Feng},\n  journal={arXiv preprint arXiv:2506.04650},\n  year={2025}\n}"
    },
    {
      "title": "Adversarial Reprogramming of Neural Networks",
      "authors": "Elsayed, G. F., Goodfellow, I., Sohl-Dickstein, J.",
      "url": "https://arxiv.org/abs/1806.11146",
      "type": "foundational",
      "description": "Introducing the concept of model reprogramming",
      "bibtex": "@inproceedings{elsayed2019adversarial,\n  title={Adversarial Reprogramming of Neural Networks},\n  author={Elsayed, Gamaleldin F and Goodfellow, Ian and Sohl-Dickstein, Jascha},\n  booktitle={International Conference on Learning Representations},\n  year={2019},\n  url={https://openreview.net/forum?id=Syx_Ss05tm}\n}"
    },
    {
      "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
      "authors": "Lester, B., Al-Rfou, R., Constant, N.",
      "url": "https://aclanthology.org/2021.emnlp-main.243/",
      "type": "foundational",
      "description": "Foundational prompt tuning research",
      "bibtex": "@inproceedings{lester2021power,\n  title={The Power of Scale for Parameter-Efficient Prompt Tuning},\n  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},\n  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},\n  pages={3045--3059},\n  year={2021},\n  url={https://aclanthology.org/2021.emnlp-main.243}\n}"
    },
    {
      "title": "Learning to Prompt for Vision-Language Models",
      "authors": "Zhou, K., Yang, J., Loy, C. C., Liu, Z.",
      "url": "https://arxiv.org/abs/2109.01134",
      "type": "foundational",
      "description": "Soft prompting tuning for Vision-Language Models on the textual branch",
      "bibtex": "@article{zhou2022learning,\n  title={Learning to Prompt for Vision-Language Models},\n  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},\n  journal={International Journal of Computer Vision},\n  volume={130},\n  number={9},\n  pages={2337--2348},\n  year={2022},\n  publisher={Springer}\n}"
    },
    {
      "title": "Language Models are Few-Shot Learners",
      "authors": "Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.",
      "url": "https://arxiv.org/abs/2005.14165",
      "type": "foundational",
      "description": "First work that demonstrates that scaling LLMs can elicit in-context learning capability",
      "bibtex": "@inproceedings{brown2020language,\n  title={Language Models are Few-Shot Learners},\n  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},\n  booktitle={Advances in Neural Information Processing Systems},\n  volume={33},\n  pages={1877--1901},\n  year={2020},\n  url={https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html}\n}"
    },
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al.",
      "url": "https://arxiv.org/abs/2201.11903",
      "type": "foundational",
      "description": "Breakthrough in instruction-based reasoning",
      "bibtex": "@inproceedings{wei2022chain,\n  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},\n  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},\n  booktitle={Advances in Neural Information Processing Systems},\n  volume={35},\n  pages={24824--24837},\n  year={2022},\n  url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html}\n}"
    },
    {
      "title": "Sample-specific Masks for Visual Reprogramming-based Prompting",
      "authors": "Cai, C., Ye, Z., Feng, L., Qi, J., Liu, F.",
      "url": "https://icml.cc/virtual/2024/poster/35002",
      "type": "recommended",
      "description": "Sample-specific masking approach for improved visual reprogramming",
      "bibtex": "@inproceedings{cai2024sample,\n  title={Sample-specific Masks for Visual Reprogramming-based Prompting},\n  author={Cai, Chengyi and Ye, Zesheng and Feng, Lei and Qi, Jianzhong and Liu, Feng},\n  booktitle={International Conference on Machine Learning},\n  year={2024},\n  note={ICML 2024 Spotlight},\n  url={https://openreview.net/forum?id=4sikyurTLX}\n}"
    },
    {
      "title": "Bayesian-guided Label Mapping for Visual Reprogramming",
      "authors": "Cai, C., Ye, Z., Feng, L., Qi, J., Liu, F.",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/1f7e17e9d60e7bc692b72f41d2178b95-Abstract-Conference.html",
      "type": "recommended",
      "description": "Probabilistic label mapping for improved visual reprogramming",
      "bibtex": "@inproceedings{cai2024bayesian,\n  title={Bayesian-guided Label Mapping for Visual Reprogramming},\n  author={Cai, Chengyi and Ye, Zesheng and Feng, Lei and Qi, Jianzhong and Liu, Feng},\n  booktitle={Advances in Neural Information Processing Systems},\n  volume={37},\n  year={2024},\n  note={NeurIPS 2024 Oral},\n  url={https://openreview.net/forum?id=135eKqDoRR}\n}"
    },
    {
      "title": "Attribute-based Visual Reprogramming for Vision-Language Models",
      "authors": "Cai, C., Ye, Z., Feng, L., Qi, J., Liu, F.",
      "url": "https://openreview.net/forum?id=j964C6y92q",
      "type": "recommended",
      "description": "Attribute-guided visual reprogramming for CLIP and vision-language models",
      "bibtex": "@inproceedings{cai2025attribute,\n  title={Attribute-based Visual Reprogramming for Vision-Language Models},\n  author={Cai, Chengyi and Ye, Zesheng and Feng, Lei and Qi, Jianzhong and Liu, Feng},\n  booktitle={International Conference on Learning Representations},\n  year={2025},\n  url={https://openreview.net/forum?id=j964C6y92q}\n}"
    },
    {
      "title": "Understanding Model Reprogramming for CLIP via Decoupling Visual Prompts",
      "authors": "Cai, C., Ye, Z., Feng, L., Qi, J., Liu, F.",
      "url": "https://icml.cc/virtual/2025/poster/45490",
      "type": "recommended",
      "description": "Decoupled visual prompts for enhanced CLIP reprogramming",
      "bibtex": "@inproceedings{cai2025understanding,\n  title={Understanding Model Reprogramming for CLIP via Decoupling Visual Prompts},\n  author={Cai, Chengyi and Ye, Zesheng and Feng, Lei and Qi, Jianzhong and Liu, Feng},\n  booktitle={International Conference on Machine Learning},\n  year={2025},\n  url={https://openreview.net/forum?id=Ne5brB1tKN}\n}"
    }
  ],
  "schedule": {
    "total_duration": "3.5 hours",
    "break_duration": "15 min",
    "session_breaks": [
      {
        "after_session": 1,
        "duration": "15 min"
      },
      {
        "after_session": 2,
        "duration": "15 min"
      }
    ]
  },
  "learning_outcomes": [
    "Understand the unified reprogrammability framework and its theoretical foundations",
    "Master the taxonomy of input manipulation techniques across different domains",
    "Apply reprogramming methods to real-world scenarios and evaluate trade-offs",
    "Assess trustworthiness implications including robustness and security considerations",
    "Implement practical solutions using provided code examples and frameworks"
  ]
}